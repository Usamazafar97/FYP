{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import numpy as np \n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split Train Folder further into Train and Validation Folders at runtime\n",
    "#reference: https://github.com/kouml/keras-split-utils/blob/master/split_utils.py\n",
    "import math\n",
    "import random\n",
    "import tempfile\n",
    "\n",
    "def _copy_symlinks(files, src_dir, dst_dir):\n",
    "    for i in files:\n",
    "        base_file_name = os.path.basename(i)\n",
    "        src_file_path = os.path.join(src_dir, base_file_name)\n",
    "        dst_file_path = os.path.join(dst_dir, base_file_name)\n",
    "        src_file_path = os.path.abspath(src_file_path)\n",
    "        dst_file_path = os.path.abspath(dst_file_path)\n",
    "        os.symlink(src_file_path, dst_file_path)\n",
    "\n",
    "def train_valid_split(original_dir, validation_split=0.1, seed=None):\n",
    "    if seed is not None:\n",
    "        random.seed(seed)    \n",
    "    if not os.path.isdir(original_dir):\n",
    "        raise NotADirectoryError\n",
    "    tmp_dir = tempfile.TemporaryDirectory()\n",
    "    train_dir = os.path.join(tmp_dir.name, 'train')\n",
    "    valid_dir = os.path.join(tmp_dir.name, 'validation')\n",
    "\n",
    "    # make subdirs in train tmp and valid tmp\n",
    "    for root, dirs, files in os.walk(original_dir):\n",
    "        if root == original_dir:\n",
    "            continue\n",
    "        sub_dir_name = os.path.basename(root)\n",
    "        train_sub_dir_path = os.path.join(train_dir, sub_dir_name)\n",
    "        valid_sub_dir_path = os.path.join(valid_dir, sub_dir_name)\n",
    "        if not os.path.exists(train_sub_dir_path):\n",
    "            os.makedirs(train_sub_dir_path)\n",
    "        if not os.path.exists(valid_sub_dir_path):\n",
    "            os.makedirs(valid_sub_dir_path)\n",
    "\n",
    "    # distribute symlinks to train_tmp, test_tmp\n",
    "    for root, dirs, files in os.walk(original_dir):\n",
    "        if root == original_dir:\n",
    "            continue\n",
    "        sub_dir_name = os.path.basename(root)\n",
    "        train_sub_dir_path = os.path.join(train_dir, sub_dir_name)\n",
    "        valid_sub_dir_path = os.path.join(valid_dir, sub_dir_name)\n",
    "        files = [os.path.join(root, f) for f in files]\n",
    "        random.shuffle(files)\n",
    "        valid_idx = math.ceil(validation_split * len(files))\n",
    "        train_files = files[valid_idx:]\n",
    "        valid_files = files[:valid_idx]\n",
    "        _copy_symlinks(train_files, root, train_sub_dir_path)\n",
    "        _copy_symlinks(valid_files, root, valid_sub_dir_path)\n",
    "    return tmp_dir, train_dir, valid_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "original_dir = '../input/complete-fruit-veg-dataset-v1/train'\n",
    "#batch size indicates number of samples/images after which weights of model are updated\n",
    "batch_size = 32\n",
    "# validation data should be 10% of training data\n",
    "validation_split = 0.1\n",
    "\n",
    "#split train folder into train and validation folders\n",
    "base_dir, train_dir, val_dir = train_valid_split(original_dir, validation_split, seed=1)\n",
    "\n",
    "#ImageDataGenerator is used for normalization of dataset and to perform Augmentations on the Data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = (1./255),\n",
    "    rotation_range=90,\n",
    "    width_shift_range=.2,\n",
    "    zoom_range=0.2,\n",
    "    height_shift_range=.2,\n",
    "    brightness_range=(0.9,1.5),\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = (1./255))\n",
    "validation_datagen = ImageDataGenerator(rescale = (1./255))\n",
    "\n",
    "# flow_from_directory supplies images from a directory, and assign labels to images according to the\n",
    "# folder name in which they are present\n",
    "# It eliminates need for having a .csv files for labels explicitly\n",
    "# target_size transforms the images to specified dimensions. In our case input layer of model accepts\n",
    "# images of dimensions 224 * 224\n",
    "# class_mode indicates if it is a binary class or multi class problem\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size= 32,\n",
    "    class_mode='binary',\n",
    "    shuffle=True)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size= 32,\n",
    "    class_mode='binary',\n",
    "    shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries building model and for training and testing purposes\n",
    "import keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()  #initialize sequential model. It allows to stack layers sequentially\n",
    "# adding convolution layers and Pooling layers\n",
    "model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "# flattening the output vector into a single dimension so that it can be fed to dense layers for prediction\n",
    "model.add(Flatten())\n",
    "# adding dense layers\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "#finally the output layer predicts the output label of image\n",
    "model.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiling the model\n",
    "model.compile(optimizer= keras.optimizers.Adam(lr=0.00001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using callback functions offered by keras to avoid overfitting and to save the best model during training\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "filepath = ('./rottenvsfresh_single_multi_classifier.h5')\n",
    "# stops training when validation loss does not improve for consecutive 4 epochs\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', verbose=0, mode='min', patience = 4)\n",
    "# saves best model with minimum loss\n",
    "mcp_save = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training/fitting the model on training data, using validation data to avoid overfitting\n",
    "history = model.fit_generator(generator=train_generator,validation_data=validation_generator,\n",
    "use_multiprocessing=True,\n",
    "workers=6,\n",
    "steps_per_epoch=math.ceil(train_generator.n//train_generator.batch_size),\n",
    "epochs = 50,\n",
    "validation_steps=math.ceil(validation_generator.n//validation_generator.batch_size),\n",
    "callbacks=[earlyStopping, mcp_save])\n",
    "\n",
    "# save the weights of model in a directory\n",
    "model.save_weights(\"./rottenvsfresh_single_multi_classifier.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plotting graph of Training accuracy with respect to Validation accuracy across various epochs\n",
    "plt.plot(history.epoch,history.history['val_accuracy'],'-b',label='Validation Accuracy')\n",
    "plt.plot(history.epoch,history.history['accuracy'],'-g',label='Training Accuracy')\n",
    "\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plotting graph of Training loss with respect to Validation loss across various epochs\n",
    "loss_train = history.history['loss']\n",
    "loss_val = history.history['val_loss']\n",
    "epochs = history.epoch\n",
    "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
    "plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Evaluation on Test Data, we first have to load our saved model\n",
    "model.load_weights(\"./rottenvsfresh_single_multi_classifier.h5\")\n",
    "\n",
    "# extract test images\n",
    "testing_generator = test_datagen.flow_from_directory(\n",
    "    '../input/complete-fruit-veg-dataset-v1/test',\n",
    "    target_size=(224, 224),\n",
    "    batch_size= 1,\n",
    "    class_mode='binary',\n",
    "    shuffle=False)\n",
    "\n",
    "# Finally test our model on the test data\n",
    "pred=model.evaluate_generator(testing_generator,\n",
    "steps=testing_generator.n,\n",
    "verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
