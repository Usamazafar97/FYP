{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#import necessary libraries\nimport numpy as np \nimport pandas as pd\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nfrom random import shuffle\nfrom keras.utils  import to_categorical","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Split Train Folder further into Train and Validation Folders at runtime\nimport math\nimport random\nimport tempfile\n\ndef _copy_symlinks(files, src_dir, dst_dir):\n    for i in files:\n        base_file_name = os.path.basename(i)\n        src_file_path = os.path.join(src_dir, base_file_name)\n        dst_file_path = os.path.join(dst_dir, base_file_name)\n        src_file_path = os.path.abspath(src_file_path)\n        dst_file_path = os.path.abspath(dst_file_path)\n        os.symlink(src_file_path, dst_file_path)\n\ndef train_valid_split(original_dir, validation_split=0.1, seed=None):\n    if seed is not None:\n        random.seed(seed)    \n    if not os.path.isdir(original_dir):\n        raise NotADirectoryError\n    tmp_dir = tempfile.TemporaryDirectory()\n    train_dir = os.path.join(tmp_dir.name, 'train')\n    valid_dir = os.path.join(tmp_dir.name, 'validation')\n\n    # make subdirs in train tmp and valid tmp\n    for root, dirs, files in os.walk(original_dir):\n        if root == original_dir:\n            continue\n        sub_dir_name = os.path.basename(root)\n        train_sub_dir_path = os.path.join(train_dir, sub_dir_name)\n        valid_sub_dir_path = os.path.join(valid_dir, sub_dir_name)\n        if not os.path.exists(train_sub_dir_path):\n            os.makedirs(train_sub_dir_path)\n        if not os.path.exists(valid_sub_dir_path):\n            os.makedirs(valid_sub_dir_path)\n\n    # distribute symlinks to train_tmp, test_tmp\n    for root, dirs, files in os.walk(original_dir):\n        if root == original_dir:\n            continue\n        sub_dir_name = os.path.basename(root)\n        train_sub_dir_path = os.path.join(train_dir, sub_dir_name)\n        valid_sub_dir_path = os.path.join(valid_dir, sub_dir_name)\n        files = [os.path.join(root, f) for f in files]\n        random.shuffle(files)\n        valid_idx = math.ceil(validation_split * len(files))\n        train_files = files[valid_idx:]\n        valid_files = files[:valid_idx]\n        _copy_symlinks(train_files, root, train_sub_dir_path)\n        _copy_symlinks(valid_files, root, valid_sub_dir_path)\n    return tmp_dir, train_dir, valid_dir","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\noriginal_dir = '../input/complete-fruit-veg-dataset-v1/train'\n#batch size indicates how many images should be fed to the model at the same time\nbatch_size = 32\n# validation data should be 10% of training data\nvalidation_split = 0.1\n\n#split train folder into train and validation folders\nbase_dir, train_dir, val_dir = train_valid_split(original_dir, validation_split, seed=1)\n\n#ImageDataGenerator is used for normalization of dataset and to perform Augmentations on the Data\ntrain_datagen = ImageDataGenerator(\n    rescale = (1./255),\n    rotation_range=90,\n    width_shift_range=.2,\n    zoom_range=0.2,\n    height_shift_range=.2,\n    brightness_range=(0.9,1.5),\n    horizontal_flip=True)\n\ntest_datagen = ImageDataGenerator(rescale = (1./255))\nvalidation_datagen = ImageDataGenerator(rescale = (1./255))\n\n# flow_from_directory supplies images from a directory, and assign labels to images according to the\n# folder name in which they are present\n# It eliminates need for having a .csv files for labels explicitly\n# target_size transforms the images to specified dimensions. In our case input layer of model accepts\n# images of dimensions 224 * 224\n# class_mode indicates if it is a binary class or multi class problem\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(224, 224),\n    batch_size= 32,\n    class_mode='categorical',\n    shuffle=True)\n\nvalidation_generator = validation_datagen.flow_from_directory(\n    val_dir,\n    target_size=(224, 224),\n    batch_size= 32,\n    class_mode='categorical',\n    shuffle=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing required libraries building model and for training and testing purposes\nimport keras \nfrom keras.layers import Conv2D,MaxPooling2D , Activation, Flatten\nfrom keras.models import Sequential\nfrom tensorflow.keras.layers import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()  #initialize sequential model. It allows to stack layers sequentially\n# adding convolution layers and Pooling layers\nmodel.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n\nmodel.add(Conv2D(filters=128, kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=128, kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n\nmodel.add(Conv2D(filters=256, kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=256, kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=256, kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n\nmodel.add(Conv2D(filters=512, kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=512, kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=512, kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n\nmodel.add(Conv2D(filters=512, kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=512, kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=512, kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n# flattening the output vector into a single dimension so that it can be fed to dense layers for prediction\nmodel.add(Flatten())\n# adding dense layers\nmodel.add(Dense(units=4096,activation=\"relu\"))\nmodel.add(Dense(units=4096,activation=\"relu\"))\n#finally the output layer predicts the output label of image\nmodel.add(Dense(units=3, activation=\"softmax\"))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#compiling the model\nmodel.compile(optimizer= keras.optimizers.Adam(lr=0.00001), loss='binary_crossentropy', metrics=['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#using callback functions offered by keras to avoid overfitting and to save the best model during training\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\n\nfilepath = ('./rottenvsfresh_single_multi_classifier.h5')\n# stops training when validation loss does not improve for consecutive 4 epochs\nearlyStopping = EarlyStopping(monitor='val_loss', verbose=0, mode='min', patience = 4)\n# saves best model with minimum loss\nmcp_save = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', mode='min')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training/fitting the model on training data, using validation data to avoid overfitting\nhistory = model.fit_generator(generator=train_generator,validation_data=validation_generator,\nuse_multiprocessing=True,\nworkers=6,\nsteps_per_epoch=math.ceil(train_generator.n//train_generator.batch_size),\nepochs = 50,\nvalidation_steps=math.ceil(validation_generator.n//validation_generator.batch_size),\ncallbacks=[earlyStopping, mcp_save])\n\n# save the weights of model in a directory\nmodel.save_weights(\"./rottenvsfresh_single_multi_classifier.h5\")\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# plotting graph of Training accuracy with respect to Validation accuracy across various epochs\nplt.plot(history.epoch,history.history['val_accuracy'],'-b',label='Validation Accuracy')\nplt.plot(history.epoch,history.history['accuracy'],'-g',label='Training Accuracy')\n\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()\n\n# plotting graph of Training loss with respect to Validation loss across various epochs\nloss_train = history.history['loss']\nloss_val = history.history['val_loss']\nepochs = history.epoch\nplt.plot(epochs, loss_train, 'g', label='Training loss')\nplt.plot(epochs, loss_val, 'b', label='validation loss')\nplt.title('Training and Validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For Evaluation on Test Data, we first have to load our saved model\nmodel.load_weights(\"./rottenvsfresh_single_multi_classifier.h5\")\n\n# extract test images\ntesting_generator = test_datagen.flow_from_directory(\n    '../input/complete-fruit-veg-dataset-v1/test',\n    target_size=(224, 224),\n    batch_size= 1,\n    class_mode='categorical',\n    shuffle=False)\n\nSTEP_SIZE_TEST=testing_generator.n    # at each step label of 1 image should be evaluated\n\n# Finally test our model on the test data\npred=model.evaluate_generator(testing_generator,\nsteps=STEP_SIZE_TEST,\nverbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}