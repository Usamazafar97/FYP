{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#import necessary libraries\nimport numpy as np \nimport pandas as pd\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom random import shuffle\nfrom keras.utils  import to_categorical\nfrom sklearn.model_selection import KFold, StratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# original directory with complete dataset\noriginal_dir =\"../input/total-cucumber-multi/Total_Cucumber_multi/Total_Cucumber\"\n# load .csv files that contains labels of images\ntotal_data = pd.read_csv('../input/total-cucumber-multi/cucumber_3.csv')\nlabels = total_data[['label']] #labels\nnames = total_data[['name']]  # filenames\n    \n# StratifiedKFold evenly splits images of all classes into folds    \nstratkf = StratifiedKFold(n_splits = 3, random_state = 7, shuffle = True)\n\n\nVAL_ACCURACIES = []  # for storing validation accuracies across each fold\nVAL_LOSSES = []   # for storing validation loss across each fold\n\nfold_count = 1 # initializing fold count to keep track of all folds\n\n# ImageDataGenerator is used for normalization of dataset and to perform Augmentations on the Data\ntrain_datagen = ImageDataGenerator(\n    rescale = (1./255),\n    rotation_range=90,\n    width_shift_range=.2, \n    height_shift_range=.2,\n    zoom_range = 0.2,\n    brightness_range=(0.9,1.5),\n    horizontal_flip=True)\n\n# No need to apply augmentation on validation data to mimic the unseen real world data\nvalidation_datagen = ImageDataGenerator(rescale = (1./255))\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# retrieve model name acrossing each fold for storing models of each fold separately\ndef getModelName(i):\n    return 'model_'+str(i)+'.h5'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing required libraries building model and for training and testing purposes\nimport keras \nfrom keras.layers import Dense,Dropout, Conv2D,MaxPooling2D , Activation, Flatten\nfrom keras.models import Sequential\nfrom tensorflow.keras.layers import *\nimport math\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, EarlyStopping\n\n# loop across all three folds\nfor tr_index, val_index in stratkf.split(names,labels):\n    training_data = total_data.iloc[tr_index]\n    validation_data = total_data.iloc[val_index]\n\n\n\n    train_generator = train_datagen.flow_from_dataframe(\n        training_data,\n        directory = original_dir,\n        target_size=(224, 224),\n        x_col = \"name\",\n        y_col = \"label\",\n        batch_size= 32,\n        class_mode='binary',\n        shuffle=True)\n\n    validation_generator = validation_datagen.flow_from_dataframe(\n        validation_data,\n        directory = original_dir,\n        target_size=(224, 224),\n        x_col = \"name\",\n        y_col = \"label\",\n        batch_size= 32,\n        class_mode='binary',\n        shuffle=True)\n    \n    model = Sequential() #initialize sequential model. It allows to stack layers sequentially\n\n    # adding convolution layers and Pooling layers\n    model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n    model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n\n    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n\n    model.add(Conv2D(filters=128, kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n    model.add(Conv2D(filters=128, kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n\n    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n\n    model.add(Conv2D(filters=256, kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n    model.add(Conv2D(filters=256, kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n    model.add(Conv2D(filters=256, kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n\n    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n\n    model.add(Conv2D(filters=512, kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n    model.add(Conv2D(filters=512, kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n    model.add(Conv2D(filters=512, kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n\n    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n\n    model.add(Conv2D(filters=512, kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n    model.add(Conv2D(filters=512, kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n    model.add(Conv2D(filters=512, kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n\n    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n    # flattening the output vector into a single dimension so that it can be fed to dense layers for prediction\n\n    model.add(Flatten())\n    # adding dense layers\n    model.add(Dense(units=4096,activation=\"relu\"))\n    model.add(Dense(units=4096,activation=\"relu\"))\n    #finally the output layer predicts the output label of image\n    model.add(Dense(units=1, activation=\"sigmoid\"))\n    # compile model\n    model.compile(optimizer= keras.optimizers.Adam(lr=0.00001), loss='binary_crossentropy', metrics=['accuracy'])\n    model.summary()\n\n\n    #using callback functions offered by keras to avoid overfitting and to save the best model during training\n    # stops training when validation loss does not improve for consecutive 4 epochs\n    earlyStopping = EarlyStopping(monitor='val_loss', verbose=0, mode='min', patience = 4)\n    # saves best model with minimum loss\n    mcp_save = ModelCheckpoint('./'+getModelName(fold_count), save_best_only=True, monitor='val_loss', mode='min')\n    \n    # Training/fitting the model on training data, using validation data to avoid overfitting\n    history = model.fit_generator(train_generator,\n                use_multiprocessing=True,\n                workers=6,\n                steps_per_epoch=math.ceil(train_generator.n//train_generator.batch_size),\n                epochs = 50,\n                validation_steps=math.ceil(validation_generator.n//validation_generator.batch_size),\n                callbacks=[earlyStopping, mcp_save],\n                validation_data=validation_generator,)\n    \n    # save model weights\n    model.load_weights(\"./model_\"+str(fold_count)+\".h5\")\n    \n    # evaluate and validate model on test data\n    result = model.evaluate_generator(generator=validation_generator,\n            steps=validation_generator.n//validation_generator.batch_size)\n\n    # store result of evaluation in a dictionary\n    result = dict(zip(model.metrics_names,result))\n\n    \n    VAL_ACCURACIES.append(result['accuracy']) #add accuracy to the list\n    VAL_LOSSES.append(result['loss'])   #add loss to the list\n    tf.keras.backend.clear_session()  #clear session\n    fold_count += 1 #increment fold count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# calculate average accuracy and loss across the folds\navg_acc = sum(VAL_ACCURACIES)/len(VAL_ACCURACIES)\navg_loss = sum(VAL_LOSSES)/len(VAL_LOSSES)\n\n# Display validation accuracy and loss across each fold\nfor i in range(3):\n    print(\"Validation Accuracy for  Fold = \"+ str(i)+\" is \"+str(VAL_ACCURACIES[i]*100) +\"  and Loss = \"+str(VAL_LOSSES[i]))\n  \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Average Accuracy = \"+str(avg_acc*100) +\"  and Average Loss = \"+str(avg_loss))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}